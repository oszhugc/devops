高可用(High Avalilability Cluster HACluster)一般由至少两台服务器组成. 高可用集群可以通过多种技术手段实现 而服务器集群是实现高可用最流行的方案之一.

集群负载在高可用集群中起着核心的控制作用,通过负载均衡软件实现故障检测和业务切换的自动换, 三大负载均衡换件--LVS,Nginx,HAProxy. 

### 1. 高可用集群基础

#### 1.1 高可用的衡量标准

高可用(High Availibale)集群通过系统的可靠性(Reliability)和可维护性(Maintainnability)来衡量. 通常使用平均无故障时间(MTTF)来衡量系统的可靠性,用平均维修时间(MTTR)来衡量系统的可维护性. 于是可用性被定义为 HA=MTTF/(MTTF=MTTR)X100%.

衡量标准如下:

* 99% - 一年宕机时间不超过4天
* 99.9% - 一年宕机时间不超过10小时
* 99.99% - 一年宕机时间不超过1小时
* 99.999% - 一年宕机时间不超过6分钟
#### 1.2 高可用的层级结构
高可用层次结构 般有四层，最底层的叫作架构层（或者叫作信息层 ，这一层负责传递心跳信

息、集群事务信息等. 作为高可用集群最基础的一层，通常需要一组服务组件来实现. 其实通信是靠这一层实现的.

往上一层是成员关系层，集群高可用对于数据一致性要求较高，像一些 Raf 算法会依赖集群成员之间的“选举”推选出一个 Maste1 节点，这一层就负责计算“票数”并统计 成员关系层实际上起到承上启下的作用，它监控着底层架构的心跳信息，当心跳信息发生变化时，便会重新生成集群状态信息，上层依靠这些信息进行资源调度分配.

再往上一层就是资源调度层（也称为资源分配层），显然这是实现资源调度分配的管理层. 作为

管理层，一般都有一个集群资源管理器（ Cluster Resource Manager, CRM ）来实现资源的调度分配，资源管理的全部操作都要通过 CRM 来实现，所以它是集群的核心组件之一, CRM 的效率对于大规模应用的调度管理起到举足轻重的作用.

最后一层是集群的顶层, 资源层(也叫应用层), 在这里运行的是整个集群的业务应用与各种对外服务, 注意: 资源层本省并不能提供任何高可用服务, 素有的高可用或者负载都依靠底层的支持, 资源层的一些资源作为调度单位有管理层在一定策略小调度管理才能形成一个服务应用的高可用架构.

#### 1.3 常见的高可用方案
* 共享存储

共享存储一般有两种模式，一种是通过网络传输数据实现在多台设备上存储数据，以达到数据

高可用，另一种是通过直接附加存储（Direct attached storage, DAS）实现在多个硬件设备上存储备份数据文件.

事实上，云时代流行的网络存储方案有多少。去看一眼 Kubemetes 文档里的支持列表就知道了，在那几十种存储方案中脱颖而出 被众人青睐甚至成为首选的方案有两个，分别是GlusterFS与CephFS ，尽管这两个方案并不是业界最先进或者说性能最好的代表，但它们都凭借着各自优良的用户体验以及独有的特性吸引了诸多企业用户.

第一个方案是 GlusterFS ，这是一个开源的分布式文件系统，它借助于TCP/IP或InfiniBand RDMA 网络将物理分布的存储资源聚集在一起，形成一个虚拟的存储池，并使用单一全局命名空间来管理数据. 它支持横向扩展（Scale-Out）, 可通过增加存储节点来提升整个系统的容量或性能，存储容量可扩展至PB, 扩展机制也是目前存储技术的热点，能有效应对容量、 性能等存储需求.

第二个方案 CephFS 则是后起之秀，凭借其高性能、易扩展、无单点故障等特点迅速成为分布式文件存储系统的一颗新星，它主要提供对象存储、块存储和文件系统（与 GlusterFS 一样兼容 POSIX 接口，可以做到像访问本地文件夹一样访问网络资源 ）三个存储服务，目前 CephFS 相较于其他“老前辈”，还比较年轻，至今还没有完善的检查修复、灾难恢复等工具.

就目前而言 GlusterFS CephFS 都是被大家认可并使用的分布式存储方案，两者的性能各有干

秋， GlusterFS与Red Hat(小红帽公司)关系密切，所以用户比较多；而CephFS独特的存取存储空间的方法正在使其成为更受用户欢迎的选择.

* 故障转移

故障转移机制(Failover)一般不会单独作为高可用方案使用，通常融合到其他高可用方案中，

作为一种辅助的技术 这种技术方案可以把故障设备迅速从服务一线撒下来，然后再逐步排查解决.

故障转移通常使用一个“心跳”线连接两台服务器 只要主服务器与备用服务器之间的脉冲或“心跳”没有中断，备用服务器就不会启用 为了热切换和防止服务中断，也可能会有第三台服务器运行备用组件待命,当检测到主服务器“心跳”报警后，备用服务器就会接管服务.

故障转移方案常见的实际应用案例有热插拔和虚拟 IP 地址等，像一些主流的 VPS 服务商都会提供虚拟 IP 快速切换后端服务器的功能，通过把服务器与虚拟 IP 绑定，可以实现在用户毫不知觉的情况下替换掉后端的设备.

* 负载均衡

负载均衡是一个很广泛的概念，但从它的作用来看的确又是一种高效的高可用方案之一, 一方面负载均衡可以减轻单一或者多个节点的负载压力 ，将整体负载均衡地分配到多个节点上去，即便其中一个节点失效，负载工具也会迅速使用备用节点顶替。另一方面，负载工具通过和 DNS 配合，把域名解析到各个节点，也可以实现跨地域的高可用方案.

* 分布集群

集群是当前高可用领域应用最广泛的方案，集群可以和其他任一方案共同完成服务高可用

群的各节点之间通过网络实现进程间的通信，应用程序可以通过网络共享内存进行消息传送，实现分布式计算. 虽然集群也是通过冗余来保证系统高可用性的，但它是侧重服务的冗余，而不是状态的冗余（当然两者都有).

### 2. 虚拟服务的实现

实现高可用,要解决的最大问题就是肌肤在均衡, 实现负载均衡的主要过程就是实现虚拟服务. 而在所有已知的可伸缩网络服务结构中, 他们都需要一个或者多个前端的负载调度器, 通过调度器的调度实现虚拟服务.

在大部分网络服务中,客户端与服务端之间都有一层或者多层代理程序. 这些代理程序便是一套完整的虚拟服务实现方案. 这些方案可以在不同层次上实现多台服务器的负载均衡. 目前集群解决网络服务性能问题的犯法可分为以下四类: DNS轮询, 客户端调度, 应用层负载调度和IP层负载均衡. 

* DNS轮询

DNS轮询也称为RR-DNS(Round-Robin Domain Name Syst), DNS 服务器会把域名轮流解析

这组服务器的不同IP地址，从而将访问负载分到各台服务器上 这是它的基本工作原理但实际上

商用的DNS负载会更为复杂（成本更大）

* 客户端调度

客户端调度的方式比较少见，也不具有普遍的适用性. 客户端调度的方案有两种，一种是让客

户端随机选取一台应用服务器，这种方式虽然避免了DNS轮询的问题却限制了用户选择客户端的权力,例如对于Web应用不同的用户浏览器都不相同无法使用这种方式平衡负载，但对于手机

应用等客户端统一的场景，这个方案却不失为一个简单有效的解决办法.另一种客户端调度方案是基于客户端内部的监控程序，通过获取服务器的负载情况，让客户端选择连接压力较小的服务器，但这增加了额外的网络流量，也不具有普遍的适用性.

* 应用层负载调度

应用层负载调度，又叫七层负载均衡,也叫反向代理负载均衡. 总之想表达的都是一个意思，不同名称而已 其结构基本上就是多台应用服务器通过高速的网络连接成一个集群系统，在前端有一个基于应用层的负载调度器 当用户访问请求到达调度器时，请求会提交给负载均衡调度器，它分析请求并根据各个应用服务器的负载情况，重写请求并发送到其中一台应用服务器，取得结果后，再返回给用户. 

这种负载方案应用非常广泛，当然它也存在一些问题 主要是系统处理开销较大，当请求到达负载均衡调度器，一直到处理结束，调度器需要进行四次从核心空间到用户空间或从用户空间到核

心空间的上下文切换和内存复制；需要进行二次 TCP 连接，一次是从用户到调度器，另一次是从调度器到应用服务器；需要对请求进行分析和重写 这些处理都需要一定的 CPU 、内存和网络等资源.当服务规模扩增时，调度器本身可能会成为系统的瓶颈。

这种方案的优点也十分突出，自定义程度高，可以根据要求设计出满足各种场景的负载要求

在后面的几个小节中都会讲解这种方案的具体实现过程。

* IP层负载调度

与应用层负载调度方案相比， IP 层负载调度的可配置程度远不及前者，但是后者的效率确实是 

最高的，因此在很多企业中都愿意选择 IP 层负载调度方案。

### 3. LVS负载均衡

LVS的全称是Linux Virtual Server(Linux 虚拟服务器），它是一个始于1998年的自由软件项目，

官网是linuxvirtualserver:org. 如今的LVS已经是了linux 准内核的一部(Linux内核从2.4版本之

后,已内置了 LVS 的各个功能模块). 

LVS 的目标是通过 LVS 提供的负载均衡技术和 Linux 操作系统实现一个成本低廉的高性能、高

可用的服务器集群 LVS 凭借着良好的可靠性、可扩展性和可操作性等特点，成为以低廉的成本实现高效服务性能的代表性解决方案.

LVS 发展到今天已是 个颇为成熟的项目,利用LVS技术可以轻松地实现高可缩放的、高可用

的网络服务,许多著名网站和组织都在使用LVS架设的集群系统，例如Linux 的门户网站, 全球著名的开源网站等

### 4. Nginx负载均衡

Nginx是与Apache( httpd 齐名的Web服务器，在全世界范围内都有极高的人气. 其中Nginx

出色的负载性能一直是它广受欢迎的原因之 ，本节将重点介绍 Nginx的负载均衡功能,相比LVS,

Nginx的负载均衡属子七层负载，在可定制性和配置上都比 LVS 要简单直观.

#### 4.1 Nginx配置文件详解
一个完整的 Nginx 配置文件结构如下：

```
main
events{
	...
}
http{
	....
	upstream project name {
		....
	}
	server {
		....
		location { 
			....
		}
	include /path/of/nginx/conf .d/*.conf; 
	}
	....
}
```
从上面可以看到，一共分为 main(全局设置)、events (项工作模式设置)、 http(http 设置）、

upstream (负载均衡设置）,server(主机设置)、 location(URL 设置）六大部分.下面逐一介

绍这六个部

* main模块

全局设置填写Nginx的全局配置，在此区域填写的内容会被应用到Nginx全局，例如修改Nginx

默认的用户名（默认为 nobody 可以在配置文件的开头加上user nginx, 这样Nginx运行的用户

就变成了nginx. 常用的全局配置项如下

  * work_processes Nginx开启的子进程数
  * error_log 定义全局错误日志文件, 可选值有:debug,info, notice,warn, error, crit.
  * pid 指定进程id的存储文件位置
  * worker_rlimit_nofile 指定Nginx进程最多可以打开的文件描述符数量
```
＃定义Nginx运行的用户和用户组
user www www ; 
# Nginx进程数(建议为CPU总核心数，或者设置为auto)
worker processes 8 ; 
# 定义全局错误日志类型
error_log /var/log/nginx/error.log info ;
＃进程文件
pid /var/run/nginx.pid; 
＃一个 Nginx 进程最多可以打开的文件描述符数目 建议与 ulimit -n 的值保持一致
worker_rlimit_nofile 65535 ;
```
一般而言, 此处的全局配置参数可以保留默认值.
* events模块

event模块用来指定Nginx的工作模式和单个进程的连接数上限，示例如下

```
events { 
＃参考事件模型可选值有：kqueue,rtsig,epoll,/dev/poll,select,poll
# epoll模型是Linux 2.6以上版本内核中的高性能网络I/O模型
# FreeBSD或者macOS,可使用queue模型
use epoll; 
＃单个进程最大连接数 默认是 1024 ，最大连接数＝连接数 进程数）
worker connections 65535;
}
```
上述进程的最大连接数受Linux系统进程的最大打开文件数的限制，只有在执行操作系统命令
ulimit - n 65536 后 worker_connections 的设置才能生效

* http模块

http部分是配置文件最核心的部分,它包括了绝大部分HTTP服务器相关属性的配置，例如是

否使用Keepalive,是否使用gzip进行压缩等，它还包括server, upstream这些子模块，这些模块都

Nginx负载均衡的重要配置部分

```
#配置http服务器
http { 
	＃文件扩展名与文件类型映射表
	include mime.types; 
	#默认文件类型
	default_type application/octet-stream; 
	#默认编
	charset utf- 8; 
	#服务器名字的 hash 表大小
	server names hash bucket size 128 ; 
	#缓冲区代理缓冲用户端请求的最大字节数
	client_body_buffer_size 128k; 
	#允许客户端请求的最大单文件字节数
	client_max_body_size lOm; 
	#开启高效文件传输模式，启用之后Nginx 会调用sendfile函数来输出文件
	#I/O负载较大的应用，建议设置为off ，以平衡磁盘与网络I/O处理速度，减少系统的负载
	
	sendfile on;
	＃开启目录列表访问(默认关闭）
	autoindex on· 
	＃防止网络阻塞
	tcp_nopush on ; 
	tcp nodelay on;
	＃长连接超时的时间 ，单位为秒
	keepalive timeout 120 ; 
	
	# gzip 模块设置
	gzip on; ＃开启 gzip 压缩输出
	gzip_min_length lk; ＃最小压缩文件的大小
	gzip_buffers 4 16k; ＃压缩缓冲区
	gzip_http_version 1.1; ＃压缩版本
	gzip comp level 2 ; ＃压缩等级
	＃压缩类型，默认已经包含 text/html ，所以下面就不用再写了
	gzip _types text/plain application/x-javascript text/css application/xml; 
	＃会在响应头加个 Vary Accept-Encoding ，可以让前端的缓存服务器缓存经过 gzip 压缩的页面
	gzip_vary on; 
	＃在开启限制 IP 连接数的时候需要使用
	limit_zone crawler $binary_remote_addr lOm; 
	
	upstream project name { 
		....
	}
	
	server { 
		....
	}
}
```
http模块的设置项非常庞杂，感兴趣的读者可以在 Ngin 官方文档中查找相关资料
[https://www.nginx.com/resources/wiki](https://www.nginx.com/resources/wiki)。

* Server模块

sever模块是http的子模块 它可以定义一个虚拟主机，基本配置示例如下：

```
server { 
	listen 2333; 
	server_name localhost www.example.com; 
	root /nginx/www/path/ ; 
	index index.php index.html index.htm; 
	charset utf-8; 
	access_log usr/local/var/log/host.access.log main ; 
	aerror_log usr/local/var/log/host.error.log error;
	....
}
```
  * server{} 表示虚拟主机配置范围
  * listen用于指定虚拟主机的服务端口
  * server_name 用于指定ip地址或者域名, 在多个域名之间用空格分开
  * root 表示在server这个虚拟主机内web服务的根目录
  * index 表示默认的首页地址
  * charset 设置网页的默认编码方式
  * access_log 指定虚拟主机访问日志的存储路径, 后面接上日志的输出格式

server模块的配置也很多, 其中  location模块也是server模块的子模块

* location 模块

location模块是nginx中可自定义程度最高的模块，location 如同它的名字一样是用来定位解

URL的，通过正则匹配,用户可以通过location 指令实现对网页的各种处理.

```
location / { 
	root /nginx/www/path ; 
	index index.php index.html index.htm; 
}
```
* upstream模块

upstream模块又称为负载均衡模块, 下面先通过一个简单的调度算法来认识这个模块

```
upstream example.com {
  fair;
  server 127.0.0.1:80;
  server 127.0.0.1:8080 down;
  server 127.0.0.1:9999 max_fails=3 fail_timeout=20s max_conns=1000;
  server 127.0.0.1:2333 backup;
}
```
在上面的例子中,通过upstream指令定义了一个负载均衡器的名称为exeample.com, 此处的名称可以任意指定, 不一定是一个域名.
其中的fair是一种负载均衡调度器算法, 其后的server表示真实服务器群组, 后面接的真实服务器ip,

down表示server不参与负载均衡, backup表示预留的备份机器,只有当其他所有的非backup机器出现故障或者异常忙碌时,才会请求backup机器,所以这台机器的负载会很小.

max_fails表示允许请求失败的次数(默认次数是1), 当超过最大次数时返回proxy_next_upstream模块定义的错误. fail_timeout表示精力max_fails次失败后暂停服务的时间. max_connts表示限制分配给后端服务器处理的最大连接数, 超过这个数量, 将不会分配新的连接给他.

#### 4.2 Nginx负载均衡模块
* 负载均衡算法
  * weight
  * ip_hash
  * url_hash
* 会话一致性

以最简单的办法就是会话一致性 - 把相同的会话请求发送到同一台后端服务器中

* 会话流出
* 后端健康监测
* 通过DNS设置HTTP负载均衡
* TCP/UDP流量的负载均衡










